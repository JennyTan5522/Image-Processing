{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f4c062",
   "metadata": {},
   "source": [
    "Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7216358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0ac4e",
   "metadata": {},
   "source": [
    "Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da519b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(img, enhancements):\n",
    "    # image preprocessing\n",
    "    gaussian = cv2.GaussianBlur(img, (3,3), cv2.BORDER_DEFAULT)\n",
    "    gray = cv2.cvtColor(gaussian, cv2.COLOR_BGR2GRAY)\n",
    "    avg = cv2.blur(gray, (3,3))\n",
    "\n",
    "    # enhancements: 1 - only contrast enhancement, 2 - only edge enhancement, 3 - both constrast and edge enhancement\n",
    "    if enhancements == 1:\n",
    "        # contrast enhancement\n",
    "        sharp = cv2.equalizeHist(avg)\n",
    "    elif enhancements == 2:\n",
    "        # edge enhancement\n",
    "        gauss = cv2.GaussianBlur(avg, (7,7), 0)\n",
    "        sharp = cv2.addWeighted(avg, 2, gauss, -1, 0)\n",
    "    else:\n",
    "        # contrast enhancement\n",
    "        he = cv2.equalizeHist(avg)\n",
    "        \n",
    "        # edge enhancement\n",
    "        gauss = cv2.GaussianBlur(he, (7,7), 0)\n",
    "        sharp = cv2.addWeighted(he, 2, gauss, -1, 0)\n",
    "\n",
    "    # otsu binarisation\n",
    "    otsu_threshold, image_result = cv2.threshold(sharp, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee52b88",
   "metadata": {},
   "source": [
    "Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7827d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(img):\n",
    "    # edge detection (i)\n",
    "    edges = cv2.Canny(image=img, threshold1=100, threshold2=200)\n",
    "\n",
    "    # closing to join gaps between edges (ii)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6899aa5",
   "metadata": {},
   "source": [
    "Contour Detection from Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8f303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_detection(img, edges):\n",
    "    # contour detection\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    approx = cv2.approxPolyDP(c, 0.01*cv2.arcLength(c, True), True)\n",
    "    \n",
    "    # Case 1: Rectangular Object\n",
    "    if len(approx) == 4:\n",
    "        # draw contour of object\n",
    "        img = cv2.drawContours(img, [c], -1, (0,255,0), 1)\n",
    "        \n",
    "        # circle corners\n",
    "        for i in range(len(approx)):\n",
    "            img = cv2.circle(img, approx[i][0], 5, (0,0,255), 1)\n",
    "\n",
    "        return approx.reshape(-1, 2)\n",
    "    # Case 2: Irregularly Shaped Object\n",
    "    else:\n",
    "        # draw contour of object\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 1)\n",
    "\n",
    "        # circle corners\n",
    "        coords = [\n",
    "            [x, y],\n",
    "            [x, y+h],\n",
    "            [x+w, y],\n",
    "            [x+w, y+h]\n",
    "        ]\n",
    "\n",
    "        for i in range(len(coords)):\n",
    "            img = cv2.circle(img, coords[i], 5, (0,0,255), 1)\n",
    "            \n",
    "        return np.array(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53424ffd",
   "metadata": {},
   "source": [
    "Floor Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a7b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_detection(img, coords):\n",
    "    # get coordinates of pixels that belong to the detected object\n",
    "    x_coords = [item[0] for item in coords]\n",
    "    y_coords = [item[1] for item in coords]\n",
    "    \n",
    "    # get pixels that are do not belongs to the detected object\n",
    "    bg = []\n",
    "\n",
    "    for i in range(img.shape[1]):\n",
    "        for j in range(img.shape[0]):\n",
    "            if i in range(min(x_coords), max(x_coords) + 1) and j in range(min(y_coords), max(y_coords) + 1):\n",
    "                continue\n",
    "            else:\n",
    "                bg.append(img[j][i])\n",
    "                \n",
    "    # get the number of pixels for each pixel value to determine colour with biggest area in the image, which is assumed as\n",
    "    # the floor\n",
    "    unique, counts = np.unique(bg, axis=0, return_counts=True)\n",
    "            \n",
    "    # construct a mask for the floor\n",
    "    upper = unique[np.argmax(counts)] + 10\n",
    "    lower = unique[np.argmax(counts)] - 10\n",
    "\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "\n",
    "    # find contours of the floor\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # draw bounding box for the contours of the floor, to be assumed as the floor area\n",
    "    height, width, _ = img.shape\n",
    "    min_x, min_y = width, height\n",
    "    max_x = max_y = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "        min_x, max_x = min(x, min_x), max(x+w, max_x)\n",
    "        min_y, max_y = min(y, min_y), max(y+h, max_y)\n",
    "\n",
    "    cv2.rectangle(img, (min_x, min_y), (max_x, max_y), (255, 0, 0), 2)\n",
    "    \n",
    "    return (min_x, min_y, max_x, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07daf0e3",
   "metadata": {},
   "source": [
    "Determine Input Image View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7142b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_view(floor_coords, img):\n",
    "    min_x, min_y, max_x, max_y = floor_coords\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    bg_w = max_x - min_x\n",
    "    bg_h = max_y - min_y\n",
    "\n",
    "    area = bg_w * bg_h\n",
    "    img_area = height * width\n",
    "\n",
    "    # img_view: 1 - top down, 2 - side view\n",
    "    # if detected floor covers more than 90% of the image area, then considered as top down view image\n",
    "    if (area / img_area) * 100 > 90:\n",
    "        return 1\n",
    "    # otherwise, it is considered as side view image\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d07e9f",
   "metadata": {},
   "source": [
    "Calculate Transform Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b14b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the order of the coordinates to [top left, top right, bottom right, bottom left]\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    \n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f084894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_axis: 1 - top, 2 - bottom; side_axis: 1 - left, 2 - right\n",
    "def output_coords(in_coords, top_angle, top_axis, side_angle, side_axis):\n",
    "    temp_coords = order_points(np.array(in_coords))\n",
    "    top_left = temp_coords[0]\n",
    "    top_right = temp_coords[1]\n",
    "    bottom_right = temp_coords[2]\n",
    "    bottom_left = temp_coords[3]\n",
    "\n",
    "    # rotation of the image with respect to the specified axis / side, rotates the horizontal view\n",
    "    if side_angle != 0:\n",
    "        if side_axis == 1:\n",
    "            new_top_right = [[], []]\n",
    "            new_bottom_right = [[], []]\n",
    "\n",
    "            new_top_right[0] = top_left[0] + ((top_right[0] - top_left[0]) * math.cos(side_angle * math.pi / 180)) + ((top_right[1] - top_left[1]) * math.sin(side_angle * math.pi / 180))\n",
    "            new_top_right[1] = top_left[1] - ((top_right[0] - top_left[0]) * math.sin(side_angle * math.pi / 180)) + ((top_right[1] - top_left[1]) * math.cos(side_angle * math.pi / 180))\n",
    "            new_bottom_right[0] = bottom_left[0] + ((bottom_right[0] - bottom_left[0]) * math.cos(side_angle * math.pi / 180)) + ((bottom_right[1] - bottom_left[1]) * math.sin(side_angle * math.pi / 180))\n",
    "            new_bottom_right[1] = bottom_left[1] - ((bottom_right[0] - bottom_left[0]) * math.sin(side_angle * math.pi / 180)) + ((bottom_right[1] - bottom_left[1]) * math.cos(side_angle * math.pi / 180))\n",
    "\n",
    "            top_right = new_top_right\n",
    "            bottom_right = new_bottom_right\n",
    "        else:\n",
    "            new_top_left = [[], []]\n",
    "            new_bottom_left = [[], []]\n",
    "            \n",
    "            new_top_left[0] = top_right[0] + ((top_left[0] - top_right[0]) * math.cos(side_angle * math.pi / 180)) + ((top_left[1] - top_right[1]) * math.sin(side_angle * math.pi / 180))\n",
    "            new_top_left[1] = top_right[1] - ((top_left[0] - top_right[0]) * math.sin(side_angle * math.pi / 180)) + ((top_left[1] - top_right[1]) * math.cos(side_angle * math.pi / 180))\n",
    "            new_bottom_left[0] = bottom_right[0] + ((bottom_left[0] - bottom_right[0]) * math.cos(side_angle * math.pi / 180)) + ((bottom_left[1] - bottom_right[1]) * math.sin(side_angle * math.pi / 180))\n",
    "            new_bottom_left[1] = bottom_right[1] - ((bottom_left[0] - bottom_right[0]) * math.sin(side_angle * math.pi / 180)) + ((bottom_left[1] - bottom_right[1]) * math.cos(side_angle * math.pi / 180))\n",
    "            \n",
    "            top_left = new_top_left\n",
    "            bottom_left = new_bottom_left\n",
    "    \n",
    "    # rotation of the image with respect to the specified axis / side, rotates the vertical view\n",
    "    if top_angle != 0:\n",
    "        if top_axis == 1:\n",
    "            new_bottom_left = [[], []]\n",
    "            new_bottom_right = [[], []]\n",
    "\n",
    "            new_bottom_left[0] = top_left[0] + ((bottom_left[0] - top_left[0]) * math.cos(top_angle * math.pi / 180)) + ((bottom_left[1] - top_left[1]) * math.sin(top_angle * math.pi / 180))\n",
    "            new_bottom_left[1] = top_left[1] - ((bottom_left[0] - top_left[0]) * math.sin(top_angle * math.pi / 180)) + ((bottom_left[1] - top_left[1]) * math.cos(top_angle * math.pi / 180))\n",
    "            new_bottom_right[0] = top_right[0] + ((bottom_right[0] - top_right[0]) * math.cos(top_angle * math.pi / 180)) + ((bottom_right[1] - top_right[1]) * math.sin(top_angle * math.pi / 180))\n",
    "            new_bottom_right[1] = top_right[1] - ((bottom_right[0] - top_right[0]) * math.sin(top_angle * math.pi / 180)) + ((bottom_right[1] - top_right[1]) * math.cos(top_angle * math.pi / 180))\n",
    "\n",
    "            bottom_left = new_bottom_left\n",
    "            bottom_right = new_bottom_right\n",
    "        else:\n",
    "            new_top_left = [[], []]\n",
    "            new_top_right = [[], []]\n",
    "            \n",
    "            new_top_left[0] = bottom_left[0] + ((top_left[0] - bottom_left[0]) * math.cos(top_angle * math.pi / 180)) + ((top_left[1] - bottom_left[1]) * math.sin(top_angle * math.pi / 180))\n",
    "            new_top_left[1] = bottom_left[1] - ((top_left[0] - bottom_left[0]) * math.sin(top_angle * math.pi / 180)) + ((top_left[1] - bottom_left[1]) * math.cos(top_angle * math.pi / 180))\n",
    "            new_top_right[0] = bottom_right[0] + ((top_right[0] - bottom_right[0]) * math.cos(top_angle * math.pi / 180)) + ((top_right[1] - bottom_right[1]) * math.sin(top_angle * math.pi / 180))\n",
    "            new_top_right[1] = bottom_right[1] - ((top_right[0] - bottom_right[0]) * math.sin(top_angle * math.pi / 180)) + ((top_right[1] - bottom_right[1]) * math.cos(top_angle * math.pi / 180))\n",
    "\n",
    "            top_left = new_top_left\n",
    "            top_right = new_top_right\n",
    "\n",
    "    return [[top_left, top_right, bottom_right, bottom_left]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f723656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates to unwarp image into centered view\n",
    "def dest_coords(shape):\n",
    "    dst = np.zeros((4, 2), dtype = \"float32\")\n",
    "    \n",
    "    dst[0] = [0, 0]\n",
    "    dst[1] = [shape[1], 0]\n",
    "    dst[2] = [shape[1], shape[0]]\n",
    "    dst[3] = [0, shape[0]]\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c413f9",
   "metadata": {},
   "source": [
    "Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0766d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get perspective transformed image according to defined angles\n",
    "# int_flag: 0 - nearest, 1 - linear, 2 - cubic\n",
    "def perspectiveTransform(img, in_coords, out_coords, int_flag):\n",
    "    query_pts = np.float32(in_coords)\n",
    "    train_pts = np.float32(out_coords)\n",
    "\n",
    "    matrix = cv2.getPerspectiveTransform(query_pts, train_pts)\n",
    "    \n",
    "    x_coords = [item[0] for item in out_coords]\n",
    "    y_coords = [item[1] for item in out_coords]\n",
    "    \n",
    "    output_size = (math.ceil(max(img.shape[1], max(x_coords))), math.ceil(max(img.shape[0], max(y_coords))))\n",
    "\n",
    "    dst = cv2.warpPerspective(img, matrix, output_size, flags=cv2.INTER_LINEAR+cv2.WARP_INVERSE_MAP)\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfb4bd",
   "metadata": {},
   "source": [
    "Overall Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8bd4117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019998550415039062\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# input image\n",
    "img = cv2.imread('image_126.jpg')\n",
    "img_copy = img.copy()\n",
    "\n",
    "preprocessed_img = image_preprocessing(img, 3)\n",
    "edges = edge_detection(preprocessed_img)\n",
    "obj_coords = contour_detection(img, edges)\n",
    "floor_coords = floor_detection(img, obj_coords)\n",
    "im_view = image_view(floor_coords, img)\n",
    "in_coords = order_points(obj_coords)\n",
    "# for case with rotation angle\n",
    "# out_coords = np.array(output_coords(in_coords, 20, 1, 20, 1)).reshape(-1, 2)\n",
    "# for case to straighten image\n",
    "out_coords = dest_coords(img.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "transformed_image = perspectiveTransform(img_copy, in_coords, out_coords, 2)\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time)\n",
    "\n",
    "cv2.imwrite('Image 4/be.png', img)\n",
    "cv2.imwrite('OpenCV/img4.png', transformed_image)\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('pt', transformed_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709a130",
   "metadata": {},
   "source": [
    "Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44b595c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1fa0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coeffs(pa, pb):\n",
    "    matrix = []\n",
    "    for p1, p2 in zip(pa, pb):\n",
    "        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n",
    "        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n",
    "\n",
    "    A = numpy.matrix(matrix, dtype=numpy.float32)\n",
    "    B = numpy.array(pb).reshape(8)\n",
    "\n",
    "    res = numpy.dot(numpy.linalg.inv(A.T * A) * A.T, B)\n",
    "    return numpy.array(res).reshape(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55880cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007999420166015625\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image_126.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_copy = Image.fromarray(np.uint8(img.copy()))\n",
    "\n",
    "preprocessed_img = image_preprocessing(img, 3)\n",
    "edges = edge_detection(preprocessed_img)\n",
    "obj_coords = contour_detection(img, edges)\n",
    "floor_coords = floor_detection(img, obj_coords)\n",
    "im_view = image_view(floor_coords, img)\n",
    "in_coords = order_points(obj_coords)\n",
    "# for case with rotation angle\n",
    "# out_coords = np.array(output_coords(in_coords, 20, 1, 20, 1)).reshape(-1, 2)\n",
    "# for case to straighten image\n",
    "out_coords = dest_coords(img.shape)\n",
    "\n",
    "width, height = img_copy.size\n",
    "x_coords = [item[0] for item in out_coords]\n",
    "y_coords = [item[1] for item in out_coords]\n",
    "\n",
    "start_time = time.time()\n",
    "coeffs = find_coeffs(np.array(in_coords), np.array(out_coords).reshape(-1, 2))\n",
    "output_size = (math.ceil(max(img.shape[1], max(x_coords))), math.ceil(max(img.shape[0], max(y_coords))))\n",
    "transformed_img = img_copy.transform(output_size, Image.PERSPECTIVE, coeffs)\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b47088",
   "metadata": {},
   "source": [
    "Scikit Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "960d7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "102a1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2084660530090332\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image_126.jpg')\n",
    "img_copy = img.copy()\n",
    "\n",
    "preprocessed_img = image_preprocessing(img, 3)\n",
    "edges = edge_detection(preprocessed_img)\n",
    "obj_coords = contour_detection(img, edges)\n",
    "floor_coords = floor_detection(img, obj_coords)\n",
    "im_view = image_view(floor_coords, img)\n",
    "in_coords = order_points(obj_coords)\n",
    "# for case with rotation angle\n",
    "# out_coords = np.array(output_coords(in_coords, 20, 1, 20, 1)).reshape(-1, 2)\n",
    "# for case to straighten image\n",
    "out_coords = dest_coords(img.shape)\n",
    "\n",
    "x_coords = [item[0] for item in out_coords]\n",
    "y_coords = [item[1] for item in out_coords]\n",
    "\n",
    "start_time = time.time()\n",
    "tform3 = skimage.transform.ProjectiveTransform()\n",
    "tform3.estimate(np.array(in_coords), np.array(out_coords).reshape(-1, 2))\n",
    "output_size = (math.ceil(max(img.shape[1], max(x_coords))), math.ceil(max(img.shape[0], max(y_coords))))\n",
    "warped = skimage.transform.warp(img_copy, tform3, output_shape=(output_size[1], output_size[0])) # (rows = height, columns = width)\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time)\n",
    "\n",
    "warped = cv2.cvtColor(skimage.img_as_ubyte(warped), cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('skimage/img4.png', warped*255)\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('pt', warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf8e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601dcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e0368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94435b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb80e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
